<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Reducing overfitting using regularization | Atma's blog</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#d4567b">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../../rss.xml">
<link rel="canonical" href="https://atmamani.github.io/projects/ml/coursera-regularization/">
<link rel="icon" href="../../../scatter-16.png" sizes="16x16">
<link rel="icon" href="../../../scatter-32.png" sizes="32x32">
<link rel="icon" href="../../../scatter-64.png" sizes="64x64">
<link rel="icon" href="../../../scatter-128.png" sizes="128x128">
<!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-113202945-1"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-113202945-1');
</script><meta name="author" content="Atma Mani">
<meta property="og:site_name" content="Atma's blog">
<meta property="og:title" content="Reducing overfitting using regularization">
<meta property="og:url" content="https://atmamani.github.io/projects/ml/coursera-regularization/">
<meta property="og:description" content="Examples of overfitting
A model is set to be over fitting, when it performs exceedingly well on training data but poorly on validation/test data. Such a model typically is of higher order and having a">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2020-05-02T14:22:08-07:00">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://atmamani.github.io/">

                <span id="blog-title">Atma's blog</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li class="dropdown">
<a href="#" class="dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Projects <b class="caret"></b></a>
            <ul class="dropdown-menu">
<li>
<a href="../../math/">Learn math with Python</a>
                    </li>
<li>
<a href="../../stats/">Learn stats with Python</a>
                    </li>
<li>
<a href="../">Machine Learning projects</a>
                    </li>
<li>
<a href="../../dl/">Deep Learning projects</a>
                    </li>
<li>
<a href="../../spatial/">Spatial analysis</a>
                    </li>
<li>
<a href="../../thermal/">Thermal remote sensing</a>
                    </li>
<li>
<a href="../../mwrs/">Microwave remote sensing</a>
                    </li>
<li>
<a href="../../fun/">Fun projects</a>
            </li>
</ul>
</li>
<li>
<a href="../../../blog/">Blog</a>
                </li>
<li>
<a href="../../../talks/">Talks</a>
                </li>
<li>
<a href="../../../books/">Books</a>
            </li>
<li class="dropdown">
<a href="#" class="dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Cheatsheets <b class="caret"></b></a>
            <ul class="dropdown-menu">
<li>
<a href="../../../cheatsheets/learning-resources/">General learning resources</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_datatypes/">Python datatypes</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_conditional_execution/">Python conditional execution</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_functions/">Python functions</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_iterations/">Python iterations</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_exception_handling/">Python exception handling</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_classes/">Python classes</a>
                    </li>
<li>
<a href="../../../images/regex-mindmap.jpg">Python regex</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/conda_cheat_sheet/">Conda basics</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/numpy/numpy_cheat_sheet_1/">NumPy basics</a>
                    </li>
<li>
<a href="../../../cheatsheets/numpy/numpy_cheat_sheet_2/">NumPy array slicing, dicing, searching</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/pandas/pandas_cheat_sheet_1/">Pandas basics</a>
                    </li>
<li>
<a href="../../../cheatsheets/pandas/pandas_cheat_sheet_2/">Pandas multilevel index, <br>    missing data, aggregation, merging</a>
                    </li>
<li>
<a href="../../../cheatsheets/pandas/pandas_cheat_sheet_3/">Productivity with Pandas</a>
                    </li>
<li>
<a href="../../../cheatsheets/pandas/pandas_data_viz_1/">Pandas data visualization</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/matplotlib/matplotlib_1/">Matplotlib basics</a>
                    </li>
<li>
<a href="../../../cheatsheets/matplotlib/matplotlib_2/">Matplotlib log scales, ticks, scientific</a>
                    </li>
<li>
<a href="../../../cheatsheets/matplotlib/matplotlib_geo/">Geographical plotting with Basemap - matplotlib toolkit</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/seaborn/seaborn_cheat_sheet_1/">Seaborn dist, joint, pair, rug plots</a>
                    </li>
<li>
<a href="../../../cheatsheets/seaborn/seaborn_cheat_sheet_2/">Seaborn categorical - bar, count, <br>violin, strip, swarm plots</a>
                    </li>
<li>
<a href="../../../cheatsheets/seaborn/seaborn_cheat_sheet_3/">Seaborn matrix, regression - heatmap, <br> cluster, regression</a>
                    </li>
<li>
<a href="../../../cheatsheets/seaborn/seaborn_cheat_sheet_4/">Seaborn grids &amp; custom - pair, facet grids <br> customization</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/plotly/plotly_cufflinks_cheat_sheet_1/">Plotly introduction</a>
                    </li>
<li>
<a href="../../../cheatsheets/plotly/plotly_cufflinks_cheat_sheet_2/">Plotly - interactive plotting</a>
                    </li>
<li>
<a href="../../../cheatsheets/plotly/plotly_geographical_plotting_1/">Plotly - geographic plotting</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/r_cheat_sheet_1/">R basics</a>
                    </li>
<li>
<a href="../../../cheatsheets/octave-1/">Octave / MATLAB - basics</a>
                    </li>
<li>
<a href="../../../cheatsheets/octave-2/">Octave - handling data</a>
                    </li>
<li>
<a href="../../../cheatsheets/js_essentials/">Javascript essentials</a>
                    </li>
<li>
<a href="../../../cheatsheets/latex-1/">Latex introduction</a>
                    </li>
<li>
<a href="../../../cheatsheets/docker-1/">Docker introduction</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/geopandas-1/">GeoPandas - IO, projections, plotting</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/geopandas-2/">GeoPandas - GP, IO, interactive plotting, geocoding</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/geopandas-3/">GeoPandas - spatial overlays, topology</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/geopandas-4/">GeoPandas - PySal, OSM data IO</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/open-geo-raster-1/">Rasterio - IO, plotting, histograms</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/open-geo-raster-2/">Rasterio - hyperspectral, SAM</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/reading-multidim-data-using-opengeotools/">Reading multi-dimensional data using open geo tools</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/postgis-1/">PostGIS - introduction</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/postgis-2/">PostGIS - SQLAlchemy, GeoAlchemy, GeoPandas</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/web-development/">Web Development</a>
                    </li>
<li>
<a href="../../../cheatsheets/html/">HTML basics</a>
            </li>
</ul>
</li>
<li>
<a href="../../../apps/">Apps</a>
                </li>
<li>
<a href="../../../rss.xml">RSS feed</a>

                
            </li>
</ul>
<!-- DuckDuckGo custom search --><form method="get" id="search" action="https://duckduckgo.com/" class="navbar-form pull-left">
<input type="hidden" name="sites" value="https://atmamani.github.io/"><input type="hidden" name="k8" value="#444444"><input type="hidden" name="k9" value="#D51920"><input type="hidden" name="kt" value="h"><input type="text" name="q" maxlength="255" placeholder="Search…" class="span2" style="margin-top: 4px;"><input type="submit" value="DuckDuckGo Search" style="visibility: hidden;">
</form>
<!-- End of custom search -->


            <ul class="nav navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Reducing overfitting using regularization</a></h1>

        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <h3 id="examples-of-overfitting">Examples of overfitting<a href="#examples-of-overfitting" class="headerlink" title="Permalink to this heading">¶</a></h3>
<p>A model is set to be over fitting, when it performs exceedingly well on training data but poorly on validation/test data. Such a model typically is of higher order and having a high variance.</p>
<p><img src="../../../images/coursera-linear-overfit.png" width="550"></p>
<p>The image above shows 3 models, the one of right is over fitting and the one on left is under fitting (has a high bias). Under fitting can happen when the model is too simple or uses too few features to model the complexity. A overfitting model has high variance because if you change or shuffle the input training set slightly, the model changes dramatically. In other words, it has high variability depending on the input set.</p>
<p><img src="../../../images/coursera-logistic-overfit.png" width="450"></p>
<p>The graphic above shows the different levels of fit for logistic regression.</p>
<h4 id="addressing-overfitting">Addressing overfitting<a href="#addressing-overfitting" class="headerlink" title="Permalink to this heading">¶</a></h4>
<p>Some options include</p>
<ol>
<li>reducing number of features. However this leads to reducing useful information available.</li>
<li>Regularization. Here, we will keep all the features, but limit or constrain the magnitude their coefficients $\theta_{j}$. This works well even when you have a lot of features.</li>
</ol>
<h3 id="regularization-for-linear-regression">Regularization for linear regression<a href="#regularization-for-linear-regression" class="headerlink" title="Permalink to this heading">¶</a></h3>
<p>Regularization is the process of applying penalty to coefficients of higher order variables. The higher the coefficients are for those variables, the higher the cost/loss is. Thus, the optimization process will move toward fits where such coefficients are smaller, close to <code>0</code>. Intuitively, this leads to a simpler model, that is less prone to overfitting. In practice, we may not know which variables are higher order polynomials. Thus, we add penalties to all coefficients. Thus, the new cost function looks like</p>
<p>$$
J(\theta) = \frac{1}{2m}[\sum_{i=1}^{m}(h_{\theta}(x_{i})-y_{i})^{2} + \lambda \sum_{j=1}^{n}\theta_{j}^{2}]
$$
where $\lambda$ is the <strong>regularization parameter</strong>. The first part of the loss function fights to get the best fit while the second fights to keep the model simple and coefficients smaller. If $\lambda$ is too high, then model results in <strong>underfitting</strong> which has a <strong>high bias</strong>. If $\lambda$ is too low, then it results in <strong>overfitting</strong> which has a <strong>high variance</strong>.</p>
<h4 id="l1-l2-lasso-ridge-regularizations">L1, L2 (Lasso, Ridge) regularizations<a href="#l1-l2-lasso-ridge-regularizations" class="headerlink" title="Permalink to this heading">¶</a></h4>
<p>In the equation above, the $\theta$ was squared in the regularization function. This is <strong>L2</strong> regularization, aka. <strong>Ridge regression</strong>. Remember this as L2 squares the coefficients ($\theta$) attached to $\lambda$. </p>
<p>Whereas, in the case of <strong>L1</strong>, the absolute value of $\theta$ is used. <strong>L1</strong> is also called <strong>Lasso regression</strong> which stands for Least Absolute Shrinkage and Selection Operator. The same cost function for lasso would look like the below:</p>
<p>$$
J(\theta) = \frac{1}{2m}[\sum_{i=1}^{m}(h_{\theta}(x_{i})-y_{i})^{2} + \lambda \sum_{j=1}^{n}|\theta_{j}|]
$$</p>
<p>Mathematically, we don't penalize $\theta_{0}$. However in practice, it makes little difference if you penalize all coefficients or if you ignore the intercept.</p>
<h4 id="computing-gradient-descent-with-regularization">Computing gradient descent with regularization<a href="#computing-gradient-descent-with-regularization" class="headerlink" title="Permalink to this heading">¶</a></h4>
<p>Computing the <strong>gradient descent</strong> for this new loss function, we get:</p>
<p>$$
\theta_{0} := \theta_{0} - \alpha\frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x_{i})-y_{i})x_{0i}
$$
$$
\theta_{j} := \theta_{j} - \alpha[\frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x_{i})-y_{i})x_{ji} - \frac{\lambda}{m}\theta_{j}]
$$
which is rewritten as
$$
\theta_{j} := \theta_{j}(1-\alpha\frac{\lambda}{m}) - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x_{i})-y_{i})x_{ji}
$$
The term $(1-\alpha\frac{\lambda}{m})$ is always <code>&lt;1</code>, which has a shrinking effect on $\theta$. Thus, for each iteration, it strives to keep it small.</p>
<h3 id="regularization-for-logistic-regression">Regularization for logistic regression<a href="#regularization-for-logistic-regression" class="headerlink" title="Permalink to this heading">¶</a></h3>
<p>The cost function of a non-regularized logistic function looks like</p>
<p>$$
J(\theta) = \frac{-1}{m}\sum_{i=1}^{m}[y_{i}log(h_{\theta}(x_{i})) + (1-y_{i})log(1-h_{\theta}(x_{i}))]
$$
to this cost function, we add the regularization parameter to get:
$$
J(\theta) = \frac{-1}{m}\sum_{i=1}^{m}[y_{i}log(h_{\theta}(x_{i})) + (1-y_{i})log(1-h_{\theta}(x_{i}))] + \frac{\lambda}{2m}\sum_{j=1}^{n}\theta_{j}^{2}
$$
The regularization term avoids penalty for bias term $\theta_{0}$.</p>
<p>The <strong>gradient descent</strong> for logistic regression with regularization is identical to that of the <strong>linear regression</strong> explained earlier, except that, the hypothesis function is a sigmoid.</p>
    </div>
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha384-3lJUsx1TJHt7BA4udB5KPnDrlkO8T6J6v/op7ui0BbCjvZ9WqV4Xm6DTP6kQ/iBH" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2022         <a href="mailto:atma.mani@outlook.com">Atma Mani</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


            <script src="../../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script>
</body>
</html>