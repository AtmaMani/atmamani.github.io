<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Neural networks - concepts | Atma's blog</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#d4567b">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../../rss.xml">
<link rel="canonical" href="https://atmamani.github.io/projects/dl/coursera-neural-nets-concepts/">
<link rel="icon" href="../../../scatter-16.png" sizes="16x16">
<link rel="icon" href="../../../scatter-32.png" sizes="32x32">
<link rel="icon" href="../../../scatter-64.png" sizes="64x64">
<link rel="icon" href="../../../scatter-128.png" sizes="128x128">
<!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-113202945-1"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-113202945-1');
</script><meta name="author" content="Atma Mani">
<meta property="og:site_name" content="Atma's blog">
<meta property="og:title" content="Neural networks - concepts">
<meta property="og:url" content="https://atmamani.github.io/projects/dl/coursera-neural-nets-concepts/">
<meta property="og:description" content="Why use neural nets?
Consider a classification problem where the decision boundary is non-linear as shown below:

We can represent non-linearity in a linear model by adding higher order features. Howe">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2022-06-08T10:27:44-07:00">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://atmamani.github.io/">

                <span id="blog-title">Atma's blog</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li class="dropdown">
<a href="#" class="dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Projects <b class="caret"></b></a>
            <ul class="dropdown-menu">
<li>
<a href="../../math/">Learn math with Python</a>
                    </li>
<li>
<a href="../../stats/">Learn stats with Python</a>
                    </li>
<li>
<a href="../../ml/">Machine Learning projects</a>
                    </li>
<li>
<a href="../">Deep Learning projects</a>
                    </li>
<li>
<a href="../../spatial/">Spatial analysis</a>
                    </li>
<li>
<a href="../../thermal/">Thermal remote sensing</a>
                    </li>
<li>
<a href="../../mwrs/">Microwave remote sensing</a>
                    </li>
<li>
<a href="../../cloud/">Cloud computing</a>
                    </li>
<li>
<a href="../../fun/">Fun projects</a>
            </li>
</ul>
</li>
<li>
<a href="../../../blog/">Blog</a>
                </li>
<li>
<a href="../../../talks/">Talks</a>
                </li>
<li>
<a href="../../../books/">Books</a>
            </li>
<li class="dropdown">
<a href="#" class="dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Cheatsheets <b class="caret"></b></a>
            <ul class="dropdown-menu">
<li>
<a href="../../../cheatsheets/learning-resources/">General learning resources</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_datatypes/">Python datatypes</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_numeric_datatypes/">Python numeric datatypes</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_conditional_execution/">Python conditional execution</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_functions/">Python functions</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_iterations/">Python iterations</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_exception_handling/">Python exception handling</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_classes/">Python classes</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_memory/">Python memory, ref counts, garbage collection</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_mutability/">Python - mutability and immutability</a>
                    </li>
<li>
<a href="../../../cheatsheets/python/python_language_optimizations/">Python - language optimizations</a>
                    </li>
<li>
<a href="../../../images/regex-mindmap.jpg">Python regex</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/conda_cheat_sheet/">Conda basics</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/numpy/numpy_cheat_sheet_1/">NumPy basics</a>
                    </li>
<li>
<a href="../../../cheatsheets/numpy/numpy_cheat_sheet_2/">NumPy array slicing, dicing, searching</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/pandas/pandas_cheat_sheet_1/">Pandas basics</a>
                    </li>
<li>
<a href="../../../cheatsheets/pandas/pandas_cheat_sheet_2/">Pandas multilevel index, <br>    missing data, aggregation, merging</a>
                    </li>
<li>
<a href="../../../cheatsheets/pandas/pandas_cheat_sheet_3/">Productivity with Pandas</a>
                    </li>
<li>
<a href="../../../cheatsheets/pandas/pandas_data_viz_1/">Pandas data visualization</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/matplotlib/matplotlib_1/">Matplotlib basics</a>
                    </li>
<li>
<a href="../../../cheatsheets/matplotlib/matplotlib_2/">Matplotlib log scales, ticks, scientific</a>
                    </li>
<li>
<a href="../../../cheatsheets/matplotlib/matplotlib_geo/">Geographical plotting with Basemap - matplotlib toolkit</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/seaborn/seaborn_cheat_sheet_1/">Seaborn dist, joint, pair, rug plots</a>
                    </li>
<li>
<a href="../../../cheatsheets/seaborn/seaborn_cheat_sheet_2/">Seaborn categorical - bar, count, <br>violin, strip, swarm plots</a>
                    </li>
<li>
<a href="../../../cheatsheets/seaborn/seaborn_cheat_sheet_3/">Seaborn matrix, regression - heatmap, <br> cluster, regression</a>
                    </li>
<li>
<a href="../../../cheatsheets/seaborn/seaborn_cheat_sheet_4/">Seaborn grids &amp; custom - pair, facet grids <br> customization</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/plotly/plotly_cufflinks_cheat_sheet_1/">Plotly introduction</a>
                    </li>
<li>
<a href="../../../cheatsheets/plotly/plotly_cufflinks_cheat_sheet_2/">Plotly - interactive plotting</a>
                    </li>
<li>
<a href="../../../cheatsheets/plotly/plotly_geographical_plotting_1/">Plotly - geographic plotting</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/r_cheat_sheet_1/">R basics</a>
                    </li>
<li>
<a href="../../../cheatsheets/octave-1/">Octave / MATLAB - basics</a>
                    </li>
<li>
<a href="../../../cheatsheets/octave-2/">Octave - handling data</a>
                    </li>
<li>
<a href="../../../cheatsheets/js_essentials/">Javascript essentials</a>
                    </li>
<li>
<a href="../../../cheatsheets/latex-1/">Latex introduction</a>
                    </li>
<li>
<a href="../../../cheatsheets/docker-1/">Docker introduction</a>
                    </li>
<li>
<a href="../../../cheatsheets/grep-1/">Grep introduction</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/geopandas-1/">GeoPandas - IO, projections, plotting</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/geopandas-2/">GeoPandas - GP, IO, interactive plotting, geocoding</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/geopandas-3/">GeoPandas - spatial overlays, topology</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/geopandas-4/">GeoPandas - PySal, OSM data IO</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/open-geo-raster-1/">Rasterio - IO, plotting, histograms</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/open-geo-raster-2/">Rasterio - hyperspectral, SAM</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/reading-multidim-data-using-opengeotools/">Reading multi-dimensional data using open geo tools</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/postgis-1/">PostGIS - introduction</a>
                    </li>
<li>
<a href="../../../cheatsheets/open-geo/postgis-2/">PostGIS - SQLAlchemy, GeoAlchemy, GeoPandas</a>
                    </li>
<li>
<a href="../../../"><hr></a>
                    </li>
<li>
<a href="../../../cheatsheets/web-development/">Web Development</a>
                    </li>
<li>
<a href="../../../cheatsheets/html/">HTML basics</a>
            </li>
</ul>
</li>
<li>
<a href="../../../apps/">Apps</a>
                </li>
<li>
<a href="../../../rss.xml">RSS feed</a>

                
            </li>
</ul>
<!-- DuckDuckGo custom search --><form method="get" id="search" action="https://duckduckgo.com/" class="navbar-form pull-left">
<input type="hidden" name="sites" value="https://atmamani.github.io/"><input type="hidden" name="k8" value="#444444"><input type="hidden" name="k9" value="#D51920"><input type="hidden" name="kt" value="h"><input type="text" name="q" maxlength="255" placeholder="Search…" class="span2" style="margin-top: 4px;"><input type="submit" value="DuckDuckGo Search" style="visibility: hidden;">
</form>
<!-- End of custom search -->


            <ul class="nav navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Neural networks - concepts</a></h1>

        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <h3 id="why-use-neural-nets">Why use neural nets?<a href="#why-use-neural-nets" class="headerlink" title="Permalink to this heading">¶</a></h3>
<p>Consider a classification problem where the decision boundary is non-linear as shown below:</p>
<p><img src="../../../images/coursera-neural-nets1.png" width="450"></p>
<p>We can represent non-linearity in a linear model by adding higher order features. However, when the original dataset already comes with a large number of features (say <code>100</code>), then feature engineered features increases by $\frac{O(n^{2})}{2}$ if we want to include <strong>quadratic features</strong>. Thus, for input data set with <code>100</code> features, the feature engineered features is in the order of <code>5000s</code>. Fitting a model on such a data set is expensive, further, the model will overfit. Furthermore, if we want to represent <strong>cubic features</strong>, then order increases to $O(n^{3})$.</p>
<h4 id="why-not-traditional-ml">Why not traditional ML?<a href="#why-not-traditional-ml" class="headerlink" title="Permalink to this heading">¶</a></h4>
<p><strong>Image classification</strong> is also a non-linear problem. This is because the algorithm sees images as matrices. In the graphic below, we build a training set that classifies cars from non-cars.</p>
<p><img src="../../../images/coursera-neural-nets2.png" width="450"></p>
<p>Each pixel in the image is now a feature. Thus a <code>50x50</code> grayscale image has <code>2500</code> features! Since the decision boundary is usually non-linear, the number of feature required for a quadratic fit is <code>3 million</code> features. Trying to fit a logistic regression to this dataset is not feasible.</p>
<h4 id="why-are-neural-nets-powerful">Why are neural nets powerful?<a href="#why-are-neural-nets-powerful" class="headerlink" title="Permalink to this heading">¶</a></h4>
<p>Neural nets mimic the biological neural nets found in animal brains. In brains, specific regions are responsible for specific functions. However, when scientists have conducted experiments where they would cut the signals from the ear to the sound processing region and rewrite the signals from eyes to it, the sound processing region now learns to process vision and functions just as good as the original vision processing engine. Similarly, they were able to repeat this for touch as well. Animal brain is effective as each region is not a bunch of complex algorithms, instead, most regions are general purpose systems built to infer data / signals.</p>
<p>An example of this approach are usecases for differently abled people shown below:</p>
<p><img src="../../../images/coursera-neural-nets3.png" width="450"></p>
<h3 id="neural-net-representation">Neural net representation<a href="#neural-net-representation" class="headerlink" title="Permalink to this heading">¶</a></h3>
<p>The physical neuron in a brain looks like below. It has a set of dendrites which act as inputs, a processing engine and the axon which acts as output.</p>
<p><img src="../../../images/coursera-neural-nets4.png" width="350"></p>
<p>ANNs model these 3 parts of the neuron as shown below. A set of inputs, multiplied by their weights are fed to an activation function, which is a logit or sigmoid function.</p>
<p><img src="../../../images/coursera-neural-nets5.png" width="400"></p>
<p>A group of neurons working together forms a neural net. The first layer is called the <strong>input layer</strong> and the last called the <strong>output layer</strong>. Sometimes, the <strong>bias</strong> is represented as an explicit node.</p>
<p><img src="../../../images/coursera-neural-nets6.png" width="400"></p>
<p><strong>Weights in a neural net</strong>: The graphic below shows how weights are applied in a neural net. The hypothesis function for each neuron takes the familiar $g(\theta^{T}X)$ form. <code>g</code> is the sigmoid function and $\theta_{i,k}^{j}$ represents the weight for <code>jth</code> layer, hidden node <code>i</code>, input node <code>k</code>. There is always a <strong>bias node</strong> which is represented with index <code>0</code>.</p>
<p><img src="../../../images/coursera-neural-nets7.png" width="700"></p>
<p>Thus, when you have <code>2</code> nodes in layer 1 (input) and <code>3</code> nodes in  layer 2, the dimension of the weight matrix for layer 2 is <code>3 x (2+1)</code>, we add <code>+1</code> to include the bias node in the first layer. Since weights is a matrix, we represent it with capital theta $\Theta$.</p>
<h5 id="vectorized-implementation-of-forward-propagation">Vectorized implementation of forward propagation<a href="#vectorized-implementation-of-forward-propagation" class="headerlink" title="Permalink to this heading">¶</a></h5>
<p>The input parameters in the previous slide can be represented as a vector $x$
$$
x = \begin{bmatrix}
    x_{0}\\
    x_{1}\\
    x_{2}\\
    x_{3}
\end{bmatrix}
$$
The activation function can be represented as $a^{(j)} = g(z^{(j)})$ where </p>
<p>$$
z^{(2)} = \begin{bmatrix}
    z_{1}^{2}\\
    z_{2}^{2}\\
    z_{3}^{2}
\end{bmatrix}
$$</p>
<p>Thus, $z^{(2)} = \Theta^{(1)}x$ and $a^{(2)} = g(z^{(2)})$. By extension, for the next layer, $z^{(3)} = \Theta^{(2)}a^{(2)}$ and $h_{\Theta}(x) = a^{(3)} = g(z^{(3)})$</p>
<h5 id="neural-nets-learn-their-own-features">Neural nets learn their own features<a href="#neural-nets-learn-their-own-features" class="headerlink" title="Permalink to this heading">¶</a></h5>
<p>If you look at the second half of the simple neural net presented earlier, it is simply a logistic regression. The inputs are however, not inputs from real world, but activations of the previous layer. Thus, neural net can create its own input features. Because of this, it is capable of representing non-linear and higher order functions, even when the real world input does not have them.</p>
<h3 id="logical-operations-with-neurons">Logical operations with neurons<a href="#logical-operations-with-neurons" class="headerlink" title="Permalink to this heading">¶</a></h3>
<p>Neurons in neural nets build complex representations using simple condition checks. Below is an example of how logical <code>AND</code>, <code>OR</code> operators are represented:</p>
<p><img src="../../../images/coursera-neural-nets8.png" width="500"></p>
<p>Then, by simply changing the weights, the same neuron can be switched to an <code>OR</code> operator:</p>
<p><img src="../../../images/coursera-neural-nets9.png" width="500"></p>
<p>Why are these useful? Many layers of such neurons can build to represent more complex decision boundaries such as <code>XOR</code> or <code>XNOR</code> or even non-linear boundaries. Below is an example of how <code>2</code> layers of NN are used to build <code>XNOR</code> gate using <code>OR</code>, <code>AND</code>, <code>NOR</code> gates. <code>XNOR</code> gives <code>1</code> if both <code>x1</code>, <code>x2</code> are <code>0</code> or <code>1</code>.</p>
<p><img src="../../../images/coursera-neural-nets11.png" width="500"></p>
<h3 id="multiclass-classification-with-nn">Multiclass classification with NN<a href="#multiclass-classification-with-nn" class="headerlink" title="Permalink to this heading">¶</a></h3>
<p>Multiclass classification in NN is essentially a <strong>on-vs-all</strong> classification. The output layer has as many nodes as the number of classes. Further, the value of the output layer looks like <strong>one-hot</strong> encoding</p>
<p><img src="../../../images/coursera-neural-nets12.png" width="550"></p>
<h4 id="ocr-on-mnist-digits-database-using-nn">OCR on MNIST digits database using NN<a href="#ocr-on-mnist-digits-database-using-nn" class="headerlink" title="Permalink to this heading">¶</a></h4>
<p>The MNIST database has <code>14</code> million images of handdrawn digits. We work with a subset of <code>5000</code> images. Each image is <code>20x20</code> pixels. When laid out as a column vector (which is how Neural Nets and log reg algorithms will read it), we get a <code>1x400</code> row vector. A sample of 100 images is below:</p>
<p><img src="../../../images/coursera-logreg-mnist1.png/" width="400"></p>
<p>When classifying these digits, we work with <code>1</code> image at a time. This is unlike linear or logistic regression where we would represent the whole training set as matrix <code>X</code>. Here, we treat each pixel as a feature. Thus our input layer has <code>400+1</code> nodes (1 added to represent bias). The hidden layer from pre-trained network has <code>25</code> nodes. The output layer should have <code>10</code> nodes to represent the <code>10</code> classes we predict.</p>
<p>Thus, input layer is x = $a^{(1)}_{401x1}$. The weight matrix</p>
<p>$$
a^{(1)} = x_{401x1}
$$</p>
<p>$$
z^{(2)} = \Theta^{(1)}_{25x401} . a^{(1)}
$$</p>
<p>$$
a^{(2)}_{25x1} = sigmoid(z^{(2)})
$$</p>
<p>We will add a bias to $a^{(2)}$ when computing the next layer, making it $a^{(2)}_{26x1}$</p>
<p>$$
z^{(3)} = \Theta^{(2)}_{10x26} . a^{(2)}
$$</p>
<p>$$
a^{(3)}_{10x1} = sigmoid(z^{(3)})
$$</p>
<p>$$
h_{\Theta}(x) = max(sigmoid(a^{(3)}))
$$</p>
<p>The implementation code can be see <a href="https://github.com/AtmaMani/pyChakras/tree/master/ml/coursera-ml-matlabonline/machine-learning-ex/ex3">here</a>.</p>
    </div>
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha384-3lJUsx1TJHt7BA4udB5KPnDrlkO8T6J6v/op7ui0BbCjvZ9WqV4Xm6DTP6kQ/iBH" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2022         <a href="mailto:atma.mani@outlook.com">Atma Mani</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


            <script src="../../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script>
</body>
</html>