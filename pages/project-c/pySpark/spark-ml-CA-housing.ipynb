{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting CA housing prices using SparkMLib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boiler plate - initialize SparkSession & Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### About CA housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Number of records: 20640\n",
    "\n",
    "variables: Lat, Long, Median Age, #rooms, #bedrooms, population in block, households, med income, med house value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cal_housing.data  cal_housing.domain\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../datasets/CaliforniaHousing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data file\n",
    "rdd = sc.textFile('../datasets/CaliforniaHousing/cal_housing.data')\n",
    "\n",
    "# load header\n",
    "header = sc.textFile('../datasets/CaliforniaHousing/cal_housing.domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdd.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-122.230000,37.880000,41.000000,880.000000,129.000000,322.000000,126.000000,8.325200,452600.000000',\n",
       " '-122.220000,37.860000,21.000000,7099.000000,1106.000000,2401.000000,1138.000000,8.301400,358500.000000',\n",
       " '-122.240000,37.850000,52.000000,1467.000000,190.000000,496.000000,177.000000,7.257400,352100.000000',\n",
       " '-122.250000,37.850000,52.000000,1274.000000,235.000000,558.000000,219.000000,5.643100,341300.000000',\n",
       " '-122.250000,37.850000,52.000000,1627.000000,280.000000,565.000000,259.000000,3.846200,342200.000000']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-122.230000',\n",
       " '37.880000',\n",
       " '41.000000',\n",
       " '880.000000',\n",
       " '129.000000',\n",
       " '322.000000',\n",
       " '126.000000',\n",
       " '8.325200',\n",
       " '452600.000000']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split by comma\n",
    "rdd = rdd.map(lambda line : line.split(','))\n",
    "\n",
    "# get the first two lines\n",
    "rdd.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert RDD to Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\n",
      "| households|housingMedianAge| latitude|  longitude|medianHouseValue|medianIncome| population|totalBedRooms| totalRooms|\n",
      "+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\n",
      "| 126.000000|       41.000000|37.880000|-122.230000|   452600.000000|    8.325200| 322.000000|   129.000000| 880.000000|\n",
      "|1138.000000|       21.000000|37.860000|-122.220000|   358500.000000|    8.301400|2401.000000|  1106.000000|7099.000000|\n",
      "| 177.000000|       52.000000|37.850000|-122.240000|   352100.000000|    7.257400| 496.000000|   190.000000|1467.000000|\n",
      "| 219.000000|       52.000000|37.850000|-122.250000|   341300.000000|    5.643100| 558.000000|   235.000000|1274.000000|\n",
      "| 259.000000|       52.000000|37.850000|-122.250000|   342200.000000|    3.846200| 565.000000|   280.000000|1627.000000|\n",
      "+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert RDD to a dataframe\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Map the RDD to a DF\n",
    "df = rdd.map(lambda line: Row(longitude=line[0], \n",
    "                              latitude=line[1], \n",
    "                              housingMedianAge=line[2],\n",
    "                              totalRooms=line[3],\n",
    "                              totalBedRooms=line[4],\n",
    "                              population=line[5], \n",
    "                              households=line[6],\n",
    "                              medianIncome=line[7],\n",
    "                              medianHouseValue=line[8])).toDF()\n",
    "\n",
    "# show the top few DF rows\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- households: string (nullable = true)\n",
      " |-- housingMedianAge: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- medianHouseValue: string (nullable = true)\n",
      " |-- medianIncome: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      " |-- totalBedRooms: string (nullable = true)\n",
      " |-- totalRooms: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert all strings to float using a User Defined Function\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def cast_columns(df):\n",
    "    for column in df.columns:\n",
    "        df = df.withColumn(column, df[column].cast(FloatType()))\n",
    "    return df\n",
    "\n",
    "new_df = cast_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+--------+---------+----------------+------------+----------+-------------+----------+\n",
      "|households|housingMedianAge|latitude|longitude|medianHouseValue|medianIncome|population|totalBedRooms|totalRooms|\n",
      "+----------+----------------+--------+---------+----------------+------------+----------+-------------+----------+\n",
      "|     126.0|            41.0|   37.88|  -122.23|        452600.0|      8.3252|     322.0|        129.0|     880.0|\n",
      "|    1138.0|            21.0|   37.86|  -122.22|        358500.0|      8.3014|    2401.0|       1106.0|    7099.0|\n",
      "+----------+----------------+--------+---------+----------------+------------+----------+-------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- households: float (nullable = true)\n",
      " |-- housingMedianAge: float (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- medianHouseValue: float (nullable = true)\n",
      " |-- medianIncome: float (nullable = true)\n",
      " |-- population: float (nullable = true)\n",
      " |-- totalBedRooms: float (nullable = true)\n",
      " |-- totalRooms: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis\n",
    "Print the summary stats of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------------+-------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "|summary|       households|  housingMedianAge|         latitude|          longitude|  medianHouseValue|      medianIncome|        population|    totalBedRooms|        totalRooms|\n",
      "+-------+-----------------+------------------+-----------------+-------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "|  count|            20640|             20640|            20640|              20640|             20640|             20640|             20640|            20640|             20640|\n",
      "|   mean|499.5396802325581|28.639486434108527|35.63186143109965|-119.56970444871473|206855.81690891474|3.8706710030346416|1425.4767441860465|537.8980135658915|2635.7630813953488|\n",
      "| stddev|382.3297528316098| 12.58555761211163|2.135952380602968|  2.003531742932898|115395.61587441359|1.8998217183639696|  1132.46212176534| 421.247905943133|2181.6152515827944|\n",
      "|    min|              1.0|               1.0|            32.54|            -124.35|           14999.0|            0.4999|               3.0|              1.0|               2.0|\n",
      "|    max|           6082.0|              52.0|            41.95|            -114.31|          500001.0|           15.0001|           35682.0|           6445.0|           39320.0|\n",
      "+-------+-----------------+------------------+-----------------+-------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature engineering\n",
    "Add more columns such as 'number of bedrooms per room', 'rooms per household'. Also scale the 'medianHouseValue' by 1000 so it falls within range of other numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn('medianHouseValue', col('medianHouseValue')/100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(households='126.000000', housingMedianAge='41.000000', latitude='37.880000', longitude='-122.230000', medianHouseValue=4.526, medianIncome='8.325200', population='322.000000', totalBedRooms='129.000000', totalRooms='880.000000')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add rooms per household\n",
    "df = df.withColumn('roomsPerHousehold', col('totalRooms')/col('households'))\n",
    "\n",
    "# add population per household (num people in the home)\n",
    "df = df.withColumn('popPerHousehold', col('population')/col('households'))\n",
    "\n",
    "# add bedrooms per room\n",
    "df = df.withColumn('bedroomsPerRoom', col('totalBedRooms')/col('totalRooms'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(households='126.000000', housingMedianAge='41.000000', latitude='37.880000', longitude='-122.230000', medianHouseValue=4.526, medianIncome='8.325200', population='322.000000', totalBedRooms='129.000000', totalRooms='880.000000', roomsPerHousehold=6.984126984126984, popPerHousehold=2.5555555555555554, bedroomsPerRoom=0.14659090909090908)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-order columns and split table into label and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['households',\n",
       " 'housingMedianAge',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'medianHouseValue',\n",
       " 'medianIncome',\n",
       " 'population',\n",
       " 'totalBedRooms',\n",
       " 'totalRooms',\n",
       " 'roomsPerHousehold',\n",
       " 'popPerHousehold',\n",
       " 'bedroomsPerRoom']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.select('medianHouseValue','households',\n",
    " 'housingMedianAge',\n",
    " 'latitude',\n",
    " 'longitude',\n",
    " 'medianIncome',\n",
    " 'population',\n",
    " 'totalBedRooms',\n",
    " 'totalRooms',\n",
    " 'roomsPerHousehold',\n",
    " 'popPerHousehold',\n",
    " 'bedroomsPerRoom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new DataFrame that explicitly labels the columns as labels and features. `DenseVector` is used to temporarily convert the data into numpy array and regroup into a named column DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "# return a tuple of first column and all other columns\n",
    "temp_data = df.rdd.map(lambda x:(x[0], DenseVector(x[1:])))\n",
    "\n",
    "#construct back a new DataFrame\n",
    "df2 = spark.createDataFrame(temp_data, ['label','features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=4.526, features=DenseVector([126.0, 41.0, 37.88, -122.23, 8.3252, 322.0, 129.0, 880.0, 6.9841, 2.5556, 0.1466])),\n",
       " Row(label=3.585, features=DenseVector([1138.0, 21.0, 37.86, -122.22, 8.3014, 2401.0, 1106.0, 7099.0, 6.2381, 2.1098, 0.1558]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale data by shifting mean to 0 and making SD = 1\n",
    "This ensures all columns have similar levels of variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=4.526, features=DenseVector([126.0, 41.0, 37.88, -122.23, 8.3252, 322.0, 129.0, 880.0, 6.9841, 2.5556, 0.1466]), features_scaled=DenseVector([0.3296, 3.2577, 17.7345, -61.0073, 4.3821, 0.2843, 0.3062, 0.4034, 2.8228, 0.2461, 2.5264])),\n",
       " Row(label=3.585, features=DenseVector([1138.0, 21.0, 37.86, -122.22, 8.3014, 2401.0, 1106.0, 7099.0, 6.2381, 2.1098, 0.1558]), features_scaled=DenseVector([2.9765, 1.6686, 17.7251, -61.0023, 4.3696, 2.1202, 2.6255, 3.254, 2.5213, 0.2031, 2.6851]))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use StandardScaler to scale the features to std normal distribution\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "s_scaler_model = StandardScaler(inputCol='features', outputCol='features_scaled')\n",
    "scaler_fn = s_scaler_model.fit(df2)\n",
    "scaled_df = scaler_fn.transform(df2)\n",
    "\n",
    "scaled_df.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = scaled_df.randomSplit([.8,.2], seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Multiple Regression\n",
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(labelCol='label', maxIter=20)\n",
    "\n",
    "linear_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.regression.LinearRegressionModel"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0011, 0.0109, -0.4173, -0.4236, 0.4188, -0.0005, 0.0001, 0.0, 0.0275, 0.0012, 3.2844])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print columns and their coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('households', 0.0011435392550412861),\n",
       " ('housingMedianAge', 0.010914556934928758),\n",
       " ('latitude', -0.41728655702892636),\n",
       " ('longitude', -0.42357898833074664),\n",
       " ('medianIncome', 0.41879550542755656),\n",
       " ('population', -0.00047200983464106163),\n",
       " ('totalBedRooms', 0.00011060741530102377),\n",
       " ('totalRooms', 4.099208155268924e-05),\n",
       " ('roomsPerHousehold', 0.027483252262545631),\n",
       " ('popPerHousehold', 0.0011993665224223444),\n",
       " ('bedroomsPerRoom', 3.2844476401153044)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(df.columns[1:], linear_model.coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-36.56273436779799"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16535"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.summary.numInstances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49805.60256405839"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.summary.meanAbsoluteError * 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, MAE on training data is off by $50,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46775402314782377"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.summary.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68392.54514549255"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.summary.rootMeanSquaredError * 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, RMSE shows fitting on training data is off by $68,392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('households', 0.0),\n",
       " ('housingMedianAge', 0.0),\n",
       " ('latitude', 0.0),\n",
       " ('longitude', 0.0),\n",
       " ('medianIncome', 0.0),\n",
       " ('population', 0.0),\n",
       " ('totalBedRooms', 0.2242631044109853),\n",
       " ('totalRooms', 0.00010585023878628697),\n",
       " ('roomsPerHousehold', 0.0),\n",
       " ('popPerHousehold', 0.011952235555041435),\n",
       " ('bedroomsPerRoom', 0.0)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(df.columns[1:], linear_model.summary.pValues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'features', 'features_scaled', 'prediction']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = linear_model.transform(test_data)\n",
    "predicted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(predictions=1.8357791571765532, labels=0.225),\n",
       " Row(predictions=-0.9555783395577535, labels=0.225)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = predicted.select('prediction').rdd.map(lambda x:x[0])\n",
    "test_labels = predicted.select('label').rdd.map(lambda x:x[0])\n",
    "\n",
    "test_predictions_labels = test_predictions.zip(test_labels)\n",
    "test_predictions_labels_df = spark.createDataFrame(test_predictions_labels, \n",
    "                                                   ['predictions','labels'])\n",
    "\n",
    "test_predictions_labels_df.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "linear_reg_eval = RegressionEvaluator(predictionCol='predictions', labelCol='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6962295496358668"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg_eval.evaluate(test_predictions_labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Errors - MAE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49690.440586665725"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean absolute error\n",
    "prediction_mae = linear_reg_eval.evaluate(test_predictions_labels_df, \n",
    "                                          {linear_reg_eval.metricName:'mae'}) * 100000\n",
    "prediction_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69622.95496358669"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "prediction_rmse = linear_reg_eval.evaluate(test_predictions_labels_df, \n",
    "                                           {linear_reg_eval.metricName:'rmse'}) * 100000\n",
    "\n",
    "prediction_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare training vs prediction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(training error, prediction error)\n",
      "(68392.54514549255, 69622.95496358669)\n",
      "(49805.60256405839, 49690.440586665725)\n"
     ]
    }
   ],
   "source": [
    "print('(training error, prediction error)')\n",
    "print((linear_model.summary.rootMeanSquaredError * 100000, prediction_rmse))\n",
    "print((linear_model.summary.meanAbsoluteError * 100000, prediction_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[63.0, 33.0, 37.93, -122.32, 2.675, 216.0, 73....</td>\n",
       "      <td>1.835779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1439.0, 8.0, 35.43, -116.57, 2.7138, 6835.0, ...</td>\n",
       "      <td>-0.955578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[15.0, 17.0, 33.92, -114.67, 1.2656, 29.0, 24....</td>\n",
       "      <td>-0.426930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[288.0, 20.0, 38.56, -121.36, 1.8288, 667.0, 3...</td>\n",
       "      <td>0.843599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[382.0, 52.0, 37.78, -122.41, 1.8519, 1055.0, ...</td>\n",
       "      <td>2.335877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  prediction\n",
       "0  [63.0, 33.0, 37.93, -122.32, 2.675, 216.0, 73....    1.835779\n",
       "1  [1439.0, 8.0, 35.43, -116.57, 2.7138, 6835.0, ...   -0.955578\n",
       "2  [15.0, 17.0, 33.92, -114.67, 1.2656, 29.0, 24....   -0.426930\n",
       "3  [288.0, 20.0, 38.56, -121.36, 1.8288, 667.0, 3...    0.843599\n",
       "4  [382.0, 52.0, 37.78, -122.41, 1.8519, 1055.0, ...    2.335877"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_pandas_df = predicted.select('features','prediction').toPandas()\n",
    "predicted_pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['features', 'prediction'], dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_pandas_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>households</th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>population</th>\n",
       "      <th>totalBedRooms</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>roomsPerHousehold</th>\n",
       "      <th>popPerHousehold</th>\n",
       "      <th>bedroomsPerRoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>37.93</td>\n",
       "      <td>-122.32</td>\n",
       "      <td>2.6750</td>\n",
       "      <td>216.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>4.698413</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>0.246622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.43</td>\n",
       "      <td>-116.57</td>\n",
       "      <td>2.7138</td>\n",
       "      <td>6835.0</td>\n",
       "      <td>1743.0</td>\n",
       "      <td>9975.0</td>\n",
       "      <td>6.931897</td>\n",
       "      <td>4.749826</td>\n",
       "      <td>0.174737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>33.92</td>\n",
       "      <td>-114.67</td>\n",
       "      <td>1.2656</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.247423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.56</td>\n",
       "      <td>-121.36</td>\n",
       "      <td>1.8288</td>\n",
       "      <td>667.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>4.277778</td>\n",
       "      <td>2.315972</td>\n",
       "      <td>0.269481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37.78</td>\n",
       "      <td>-122.41</td>\n",
       "      <td>1.8519</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>2.654450</td>\n",
       "      <td>2.761780</td>\n",
       "      <td>0.416174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   households  housingMedianAge  latitude  longitude  medianIncome  \\\n",
       "0        63.0              33.0     37.93    -122.32        2.6750   \n",
       "1      1439.0               8.0     35.43    -116.57        2.7138   \n",
       "2        15.0              17.0     33.92    -114.67        1.2656   \n",
       "3       288.0              20.0     38.56    -121.36        1.8288   \n",
       "4       382.0              52.0     37.78    -122.41        1.8519   \n",
       "\n",
       "   population  totalBedRooms  totalRooms  roomsPerHousehold  popPerHousehold  \\\n",
       "0       216.0           73.0       296.0           4.698413         3.428571   \n",
       "1      6835.0         1743.0      9975.0           6.931897         4.749826   \n",
       "2        29.0           24.0        97.0           6.466667         1.933333   \n",
       "3       667.0          332.0      1232.0           4.277778         2.315972   \n",
       "4      1055.0          422.0      1014.0           2.654450         2.761780   \n",
       "\n",
       "   bedroomsPerRoom  \n",
       "0         0.246622  \n",
       "1         0.174737  \n",
       "2         0.247423  \n",
       "3         0.269481  \n",
       "4         0.416174  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "predicted_pandas_df2 = pd.DataFrame(predicted_pandas_df['features'].values.tolist(), \n",
    "                                   columns=df.columns[1:])\n",
    "\n",
    "predicted_pandas_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_pandas_df2['predictedHouseValue'] = predicted_pandas_df['prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to disk as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_pandas_df2.to_csv('CA_house_prices_predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA_house_prices_predicted.csv  spark_sanity.ipynb\r\n",
      "ensure_machine.ipynb\t       spark-warehouse\r\n",
      "hello-world.ipynb\t       Untitled.ipynb\r\n",
      "spark-ml-CA-housing.ipynb      using-spark-dataframes.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 12)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_pandas_df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Publish to GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter password: ········\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from arcgis.gis import GIS\n",
    "gis = GIS(\"https://www.arcgis.com\",\"arcgis_python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from arcgis.features import SpatialDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>households</th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>population</th>\n",
       "      <th>totalBedRooms</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>roomsPerHousehold</th>\n",
       "      <th>popPerHousehold</th>\n",
       "      <th>bedroomsPerRoom</th>\n",
       "      <th>predictedHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>37.93</td>\n",
       "      <td>-122.32</td>\n",
       "      <td>2.6750</td>\n",
       "      <td>216.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>4.698413</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>0.246622</td>\n",
       "      <td>1.835779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.43</td>\n",
       "      <td>-116.57</td>\n",
       "      <td>2.7138</td>\n",
       "      <td>6835.0</td>\n",
       "      <td>1743.0</td>\n",
       "      <td>9975.0</td>\n",
       "      <td>6.931897</td>\n",
       "      <td>4.749826</td>\n",
       "      <td>0.174737</td>\n",
       "      <td>-0.955578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>33.92</td>\n",
       "      <td>-114.67</td>\n",
       "      <td>1.2656</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.247423</td>\n",
       "      <td>-0.426930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.56</td>\n",
       "      <td>-121.36</td>\n",
       "      <td>1.8288</td>\n",
       "      <td>667.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>4.277778</td>\n",
       "      <td>2.315972</td>\n",
       "      <td>0.269481</td>\n",
       "      <td>0.843599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37.78</td>\n",
       "      <td>-122.41</td>\n",
       "      <td>1.8519</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>2.654450</td>\n",
       "      <td>2.761780</td>\n",
       "      <td>0.416174</td>\n",
       "      <td>2.335877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   households  housingMedianAge  latitude  longitude  medianIncome  \\\n",
       "0        63.0              33.0     37.93    -122.32        2.6750   \n",
       "1      1439.0               8.0     35.43    -116.57        2.7138   \n",
       "2        15.0              17.0     33.92    -114.67        1.2656   \n",
       "3       288.0              20.0     38.56    -121.36        1.8288   \n",
       "4       382.0              52.0     37.78    -122.41        1.8519   \n",
       "\n",
       "   population  totalBedRooms  totalRooms  roomsPerHousehold  popPerHousehold  \\\n",
       "0       216.0           73.0       296.0           4.698413         3.428571   \n",
       "1      6835.0         1743.0      9975.0           6.931897         4.749826   \n",
       "2        29.0           24.0        97.0           6.466667         1.933333   \n",
       "3       667.0          332.0      1232.0           4.277778         2.315972   \n",
       "4      1055.0          422.0      1014.0           2.654450         2.761780   \n",
       "\n",
       "   bedroomsPerRoom  predictedHouseValue  \n",
       "0         0.246622             1.835779  \n",
       "1         0.174737            -0.955578  \n",
       "2         0.247423            -0.426930  \n",
       "3         0.269481             0.843599  \n",
       "4         0.416174             2.335877  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = SpatialDataFrame.from_csv('CA_house_prices_predicted.csv')\n",
    "sdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FeatureCollection>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses_predicted_fc = gis.content.import_data(sdf[:999])\n",
    "houses_predicted_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22270f33123848ba89515ab30a55e6cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ca_map = gis.map('California')\n",
    "ca_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./ca-house-price-map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "ca_map.add_layer(houses_predicted_fc, {'renderer':'ClassedColorRenderer',\n",
    "                                      'field_name':'predictedHouseValue'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./spark-active-job-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./spark-timeline-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
